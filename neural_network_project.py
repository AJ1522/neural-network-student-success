# -*- coding: utf-8 -*-
"""Neural_Network Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cl1wavWH-VAJdd5CBxwJ53263ngGThFd
"""

import pandas as pd
from sklearn.preprocessing import OneHotEncoder

from google.colab import files
uploaded = files.upload()

# Loading the dataset
df = pd.read_csv('CourseDFWI (1).csv')

df.head()

# Checkint for categorical columns and convert them
print(df.dtypes)

# Encoding categorical variables
df = pd.get_dummies(df, columns=['course'], drop_first=True)  # Create dummy variables

# Checking the dataset after encoding to make sure all columns are numeric now
print(df.head())

# Convert dummy variables (True/False) to integers (1/0)
df = df.astype(int)

# Verify the changes
print(df.head())

# Split data into features and target variable
X = df.drop('DFWINC', axis=1)  # Features
y = df['DFWINC']  # Target

# Splitting into train, validation, and test sets
from sklearn.model_selection import train_test_split

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

import numpy as np

X_train = np.array(X_train).astype('float32')
X_val = np.array(X_val).astype('float32')
X_test = np.array(X_test).astype('float32')
y_train = np.array(y_train).astype('float32')
y_val = np.array(y_val).astype('float32')
y_test = np.array(y_test).astype('float32')

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Define the model architecture
model = Sequential()

# Input layer and one hidden layer with 5 neurons and sigmoid activation
model.add(Dense(5, input_dim=X_train.shape[1], activation='sigmoid'))

# Output layer with sigmoid activation for binary classification
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Print model summary to verify the architecture
model.summary()

# Train the model
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=32)

# Evaluate the model on the test data
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {test_accuracy:.2f}')
print(f'Test Loss: {test_loss:.4f}')

import matplotlib.pyplot as plt

# Plotting the training & validation accuracy values
plt.figure(figsize=(10, 6))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

# Plotting the training & validation loss values
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')
plt.grid(True)
plt.show()

# Make predictions
y_pred_prob = model.predict(X_test)

# Convert probabilities to binary predictions (0 or 1) using a threshold of 0.5
y_pred = (y_pred_prob > 0.5).astype(int)

# Print some sample predictions
print("Predicted labels: ", y_pred[:10].flatten())
print("Actual labels: ", y_test[:10])

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Generate a confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Successful', 'Successful'], yticklabels=['Not Successful', 'Successful'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

from sklearn.metrics import classification_report

# Print a classification report
print(classification_report(y_test, y_pred, target_names=['Not Successful', 'Successful']))

from sklearn.metrics import roc_curve, auc

# Predict probabilities
y_pred_prob = model.predict(X_test)

# Calculate ROC curve
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='grey', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()